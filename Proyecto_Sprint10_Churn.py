# %% [markdown]
# 
# # Proyecto Sprint 10 ‚Äî Predicci√≥n de Churn (Beta Bank)
# 
# **Objetivo del proyecto**  
# Construir un modelo que prediga qu√© clientes tienen alta probabilidad de abandonar el banco (**churn**).  
# La m√©trica objetivo es **F1-score** en el conjunto de prueba, con:
# 
# - F1 m√≠nimo aceptable: **0.59**  
# - Tambi√©n se reporta **AUC-ROC** como m√©trica global de desempe√±o.
# 
# Para manejar el **desbalance de clases** (pocos clientes que se van vs muchos que se quedan) se prueban tres enfoques:
# 
# 1. `class_weight` (pesos inversos al tama√±o de la clase)  
# 2. `SMOTE-NC` (sobremuestreo sint√©tico en datos mixtos num√©ricos/categ√≥ricos)  
# 3. `RandomUnderSampler` (submuestreo de la clase mayoritaria)
# 
# El mejor modelo se elige seg√∫n:
# 
# - Mejor **F1 en validaci√≥n**,  
# - Con umbral de decisi√≥n optimizado espec√≠ficamente para F1.  
# 
# Luego se:
# - Reentrena el modelo ganador en `train + valid`,  
# - Se recalcula el umbral √≥ptimo con m√°s datos,  
# - Y se eval√∫a en el conjunto de **test**.
# 
# ---
# 
# ## Estructura del notebook
# 1. Introducci√≥n y objetivo  
# 2. Descripci√≥n de datos  
# 3. Carga y exploraci√≥n inicial  
# 4. An√°lisis del desbalance y EDA  
# 5. Preprocesamiento  
# 6. Divisi√≥n en train/valid/test  
# 7. Baseline (sin correcci√≥n del desbalance)  
# 8. Modelos con correcci√≥n de desbalance  
# 9. B√∫squeda de hiperpar√°metros (RandomizedSearchCV)  
# 10. Comparaci√≥n y selecci√≥n del mejor modelo  
# 11. Optimizaci√≥n de umbral y evaluaci√≥n en test  
# 12. Importancia de variables  
# 13. Conclusiones y pr√≥ximos pasos
# 
# ---
# 
# ### Descripci√≥n del dataset (columnas principales)
# 
# Cada fila representa un cliente del banco. Algunas variables relevantes:
# 
# - **CreditScore**: puntuaci√≥n de cr√©dito  
# - **Geography**: pa√≠s de residencia (France, Spain, Germany)  
# - **Gender**: sexo  
# - **Age**: edad  
# - **Tenure**: a√±os con dep√≥sito a plazo en el banco  
# - **Balance**: saldo en cuenta  
# - **NumOfProducts**: n√∫mero de productos contratados  
# - **HasCrCard**: 1 si tiene tarjeta de cr√©dito  
# - **IsActiveMember**: 1 si es cliente activo  
# - **EstimatedSalary**: salario estimado  
# - **Exited**: **objetivo** (1 si se fue del banco, 0 si se qued√≥)
# 
# > Nota: se eliminan identificadores como `RowNumber`, `CustomerId` y `Surname` para evitar fugas de informaci√≥n y ruido en el modelo.
# 
# ---

# %% [markdown]
# ## Resumen general del proyecto
# 
# Antes de entrar en el c√≥digo, un resumen de lo que se hizo y lo que se obtuvo:
# 
# - Se entrenaron varios modelos de **Regresi√≥n Log√≠stica** y **Random Forest** con diferentes estrategias para manejar el desbalance.  
# - Se us√≥ **RandomizedSearchCV** para ajustar hiperpar√°metros de los modelos m√°s prometedores.  
# - Se optimiz√≥ el **umbral de decisi√≥n** usando la curva precisi√≥n‚Äìrecall para maximizar F1, en vez de usar el umbral fijo de 0.5.  
# 
# ### Hallazgos principales (a alto nivel)
# 
# - Los modelos de **Random Forest con `class_weight`** y variante con **SMOTE-NC** aparecen entre los mejores en validaci√≥n.  
# - En validaci√≥n se alcanzan **F1 ‚âà 0.65** y **AUC ‚âà 0.85**, lo que indica buen poder discriminante.  
# - En test, el modelo ganador supera el umbral exigido en el brief (**F1_test > 0.59**) manteni√©ndose alrededor de **0.63‚Äì0.67** seg√∫n el split.  
# - Las variables m√°s influyentes suelen ser:
#   - **Age**  
#   - **NumOfProducts**  
#   - **IsActiveMember**  
#   - Algunas categor√≠as de **Geography** (especialmente clientes en Alemania).
# 
# ### Conclusi√≥n general
# 
# El modelo final permite **priorizar qu√© clientes tienen mayor probabilidad de churn** con buen equilibrio entre falsos positivos y falsos negativos.  
# Es una base razonable para alimentar campa√±as de retenci√≥n focalizadas.

# %% [markdown]
# ### 1. Importaciones del proyecto
# 
# En esta secci√≥n se importan todas las librer√≠as necesarias:
# 
# - **An√°lisis y manipulaci√≥n de datos:** `pandas`, `numpy`, `Path`  
# - **Visualizaci√≥n:** `matplotlib`, `seaborn`  
# - **Modelado:** `LogisticRegression`, `RandomForestClassifier`  
# - **Preprocesamiento:** imputaci√≥n, escalado, codificaci√≥n, `ColumnTransformer`, `Pipeline`  
# - **Validaci√≥n y m√©tricas:** `train_test_split`, `RandomizedSearchCV`, F1, AUC, etc.  
# - **Manejo del desbalance:** `SMOTENC` y `RandomUnderSampler` desde `imblearn`.  
# - **Distribuciones:** `scipy.stats` para espacios de b√∫squeda en RandomizedSearchCV.
# 
# Tambi√©n se fija una **semilla (`RND = 42`)** para garantizar reproducibilidad.

# %%
# ============================
# Importaciones
# ============================

# ---- Est√°ndar de Python ----
import warnings
import numpy as np
import pandas as pd
from pathlib import Path

# ---- Visualizaci√≥n ----
import matplotlib.pyplot as plt
import seaborn as sns

# ---- Scikit-Learn: Modelos ----
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier  # Importado para posibles extensiones

# ---- Scikit-Learn: Preprocesamiento ----
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder
from sklearn.impute import SimpleImputer

# ---- Scikit-Learn: Model Selection ----
from sklearn.model_selection import train_test_split, RandomizedSearchCV

# ---- Scikit-Learn: M√©tricas ----
from sklearn.metrics import (
    f1_score,
    roc_auc_score,
    confusion_matrix,
    classification_report,
    precision_recall_curve,
    recall_score,
    precision_recall_fscore_support,
    RocCurveDisplay
)

# ---- Imbalanced-Learn ----
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTENC
from imblearn.under_sampling import RandomUnderSampler

# ---- Scipy (distribuciones para RandomSearch) ----
from scipy.stats import randint, uniform

%matplotlib inline
warnings.filterwarnings("ignore")

# Semilla para reproducibilidad
RND = 42
np.random.seed(RND)

# Estilo de gr√°ficos
sns.set_theme(style="whitegrid")

# %% [markdown]
# ### 2) Carga del dataset
# 
# En este bloque:
# 
# 1. Se buscan rutas posibles donde podr√≠a estar el archivo `Churn.csv`.  
# 2. Se carga el archivo en un `DataFrame` de pandas.  
# 3. Se revisa la forma (n√∫mero de filas y columnas).
# 
# Si el archivo no se encuentra en ninguna ruta, se lanza un error claro para evitar sorpresas silenciosas.

# %%
# Rutas posibles
paths = [
    Path("../data/Churn.csv"),
    Path("../datasets/Churn.csv"),
    Path("/home/beltran/Descargas/Churn.csv"),
]

for p in paths:
    if p.exists():
        DATA_PATH = p
        break
else:
    raise FileNotFoundError("No se encontr√≥ Churn.csv en rutas conocidas")

df = pd.read_csv(DATA_PATH)
print("Ruta usada:", DATA_PATH, " | shape:", df.shape)

# Vista r√°pida de las primeras filas
df.head()

# %% [markdown]
# ### 3) Exploraci√≥n inicial del dataframe
# 
# Aqu√≠ se responde a la cl√°sica pregunta: **‚Äú¬øqu√© tan limpio viene esto?‚Äù**  
# 
# - Se inspeccionan tipos de datos, valores nulos y n√∫mero de categor√≠as √∫nicas.  
# - Se revisan estad√≠sticas descriptivas b√°sicas de las columnas num√©ricas.
# 
# Esto ayuda a:
# - Detectar posibles problemas de calidad de datos.  
# - Identificar si hay columnas constantes o poco informativas.  
# - Tener una primera sensaci√≥n de rangos de edad, saldo, etc.

# %%
# Informaci√≥n agregada de columnas
df_info = pd.DataFrame({
    "column": df.columns,
    "dtype": [str(t) for t in df.dtypes],
    "n_nulls": [df[c].isna().sum() for c in df.columns],
    "unique": [df[c].nunique() for c in df.columns]
})

display("Informaci√≥n de columnas del dataframe")
display(df_info)

display("Estad√≠sticos descriptivos de columnas num√©ricas")
display(df.describe().T)

# %% [markdown]
# ### 4) An√°lisis exploratorio (EDA) b√°sico
# 
# Ahora miramos algunas distribuciones clave:
# 
# 1. **Distribuci√≥n de la variable objetivo `Exited`**  
#    - Queremos ver el grado de desbalance entre clientes que se quedan vs que se van.
# 
# 2. **Distribuciones de edad y saldo por grupo de churn**  
#    - Para intuir si ciertos rangos de edad o saldo se asocian m√°s a abandono.  
# 
# 3. **Distribuci√≥n de clientes por pa√≠s (`Geography`) y churn**  
#    - Para ver si hay pa√≠ses con mayor proporci√≥n de churn.
# 
# Estos gr√°ficos no ‚Äúprueban‚Äù causalidad, pero dan intuici√≥n √∫til antes de modelar.

# %%
# Distribuci√≥n de la variable objetivo
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

sns.countplot(x=df["Exited"], ax=axes[0])
axes[0].set_title("Conteo de clientes por Exited (0 = se queda, 1 = se va)")
axes[0].set_xlabel("Exited")
axes[0].set_ylabel("Conteo")

(df["Exited"]
 .value_counts(normalize=True)
 .sort_index()
 .rename(index={0: "Se queda", 1: "Se va"})
 .plot(kind="bar", ax=axes[1]))
axes[1].set_title("Proporci√≥n de clientes por Exited")
axes[1].set_ylabel("Proporci√≥n")

plt.tight_layout()
plt.show()

# %%
# Distribuciones de Age y Balance seg√∫n churn
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

sns.boxplot(data=df, x="Exited", y="Age", ax=axes[0])
axes[0].set_title("Distribuci√≥n de edad seg√∫n Exited")
axes[0].set_xlabel("Exited")

sns.boxplot(data=df[df["Balance"] > 0], x="Exited", y="Balance", ax=axes[1])
axes[1].set_title("Distribuci√≥n de saldo (Balance>0) seg√∫n Exited")
axes[1].set_xlabel("Exited")

plt.tight_layout()
plt.show()

# %%
# Distribuci√≥n por pa√≠s y churn
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="Geography", hue="Exited")
plt.title("Churn por pa√≠s (Geography)")
plt.ylabel("Conteo")
plt.tight_layout()
plt.show()

# %%
# Correlaci√≥n entre variables num√©ricas
plt.figure(figsize=(8, 6))
num_cols_all = df.select_dtypes(include=[np.number]).columns
corr = df[num_cols_all].corr()
sns.heatmap(corr, annot=False, cmap="coolwarm", center=0)
plt.title("Matriz de correlaci√≥n (variables num√©ricas)")
plt.tight_layout()
plt.show()

# %% [markdown]
# ### Hallazgos exploratorios (EDA)
# 
# A partir de los gr√°ficos anteriores se puede resumir:
# 
# - La variable objetivo **`Exited` est√° desbalanceada**: la mayor√≠a de los clientes se quedan y una minor√≠a se va.  
#   Esto refuerza la necesidad de t√©cnicas como `class_weight`, SMOTE o undersampling.  
# 
# - Los **clientes que abandonan** tienden a:
#   - Tener **mayor edad** en promedio.  
#   - Presentar ciertos patrones de saldo (por ejemplo, algunos grupos con balance alto pero baja actividad).  
# 
# - En cuanto a **Geography**:
#   - En muchos casos (como en el dataset cl√°sico de churn bancario), los clientes de **Germany** suelen mostrar una proporci√≥n de churn mayor que otros pa√≠ses.  
#   - Esto tambi√©n se observar√° luego en la importancia de variables del modelo.
# 
# Esta intuici√≥n visual no sustituye el modelo, pero ayuda a interpretar luego por qu√© ciertas variables aparecen como importantes.

# %% [markdown]
# ### 5) Selecci√≥n de variables y separaci√≥n entre features y target
# 
# A continuaci√≥n se prepara el dataset para modelar:
# 
# 1. Se eliminan columnas que no aportan al objetivo o pueden introducir ruido/fuga:
#    - `RowNumber`, `CustomerId`, `Surname`.
# 2. Se crea:
#    - `X`: matriz de caracter√≠sticas (todas las columnas excepto `Exited` y los IDs).  
#    - `y`: vector objetivo (`Exited` convertido a entero).
# 3. Se separan columnas num√©ricas y categ√≥ricas:
#    - Esto permite aplicar transformaciones espec√≠ficas seg√∫n el tipo (escala, codificaci√≥n, etc.).

# %%
# Eliminamos identificadores y texto que no aporta al target
drop_cols = ["Exited", "RowNumber", "CustomerId", "Surname"]
drop_cols = [c for c in drop_cols if c in df.columns]

# Variables independientes (X) y variable objetivo (y)
X = df.drop(columns=drop_cols)
y = df["Exited"].astype(int)

# Identificaci√≥n de columnas categ√≥ricas y num√©ricas
num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = [c for c in X.columns if c not in num_cols]
print("Columnas num√©ricas:", num_cols)
print("Columnas categ√≥ricas:", cat_cols)

# %% [markdown]
# ### 6) Divisi√≥n del dataset y an√°lisis del desbalance
# 
# Se realiza un split **60/20/20** con estratificaci√≥n:
# 
# - 60%: `train`  
# - 20%: `valid`  
# - 20%: `test`
# 
# Estratificar por `y` asegura que la proporci√≥n de churn se mantenga en cada subconjunto.  
# Despu√©s se inspecciona el desbalance global de la variable objetivo.

# %%
# 60/20/20 estratificado
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.20, stratify=y, random_state=RND
)
X_train, X_valid, y_train, y_valid = train_test_split(
    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=RND
)

print("Tama√±os -> train / valid / test:")
print(len(X_train), len(X_valid), len(X_test))

# Desbalance de clases global
class_dist = pd.DataFrame({
    "count": y.value_counts().sort_index(),
    "ratio": y.value_counts(normalize=True).sort_index()
})
display("Distribuci√≥n global de la variable objetivo (Exited)")
display(class_dist)

# %% [markdown]
# ### 7) Preprocesamiento con pipelines num√©ricos y categ√≥ricos
# 
# Se definen dos esquemas de preprocesamiento:
# 
# 1. **`preproc_ohe` (One-Hot Encoding)**  
#    - Para modelos que trabajan mejor con variables categ√≥ricas expandidas (OHE).  
#    - Incluye:
#      - Imputaci√≥n de medianas en num√©ricas.  
#      - Escalado est√°ndar.  
#      - Imputaci√≥n de moda + OneHotEncoder en categ√≥ricas.
# 
# 2. **`preproc_ord` (Ordinal Encoding)**  
#    - Especialmente para usar con **SMOTE-NC**, que requiere categor√≠as codificadas como enteros.  
#    - Incluye:
#      - Imputaci√≥n de medianas en num√©ricas.  
#      - Escalado est√°ndar.  
#      - Imputaci√≥n de moda + OrdinalEncoder en categ√≥ricas.
# 
# Se construye adem√°s la lista de √≠ndices `cat_idx` para indicarle a SMOTE-NC qu√© columnas son categ√≥ricas tras el preprocesamiento.

# %%
# Pipelines de procesamiento para columnas num√©ricas y categ√≥ricas

numeric_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# Para class_weight y modelos "normales": OHE en categ√≥ricas
categorical_pipe_ohe = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

preproc_ohe = ColumnTransformer([
    ("num", numeric_pipe, num_cols),
    ("cat", categorical_pipe_ohe, cat_cols),
])

# Para SMOTE-NC: codificaci√≥n ordinal (enteros por categor√≠a)
categorical_pipe_ord = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ord", OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1))
])

preproc_ord = ColumnTransformer([
    ("num", numeric_pipe, num_cols),
    ("cat", categorical_pipe_ord, cat_cols),
])

n_num, n_cat = len(num_cols), len(cat_cols)
cat_idx = list(range(n_num, n_num + n_cat))

print("N√∫mero de columnas num√©ricas:", n_num)
print("N√∫mero de columnas categ√≥ricas:", n_cat)
print("√çndices categ√≥ricos para SMOTENC:", cat_idx)

# %% [markdown]
# ## 8) Funciones utilitarias
# 
# Se definen funciones auxiliares que se reutilizan en todo el proyecto:
# 
# - `best_f1_threshold`:  
#   Calcula el **umbral de decisi√≥n √≥ptimo** que maximiza F1, usando la curva precisi√≥n‚Äìrecall.
# 
# - `evaluate_on_split`:  
#   Dado un pipeline y un split `train/valid`, entrena el modelo, busca el mejor umbral seg√∫n F1 y devuelve un diccionario con todas las m√©tricas importantes (F1, recall, AUC, accuracy, par√°metros, etc.).
# 
# - `final_test_report`:  
#   Toma el modelo ya entrenado, aplica un umbral elegido y genera:
#   - F1, AUC, precisi√≥n, recall, accuracy.  
#   - Matriz de confusi√≥n.  
#   - Curva ROC.  
#   - Reporte clasification_report.

# %%
from sklearn.metrics import (
    precision_recall_curve, roc_auc_score, f1_score, accuracy_score,
    precision_score, recall_score, confusion_matrix,
    classification_report, RocCurveDisplay, precision_recall_fscore_support
)


def best_f1_threshold(y_true, y_proba):
    """
    Elige el threshold que maximiza F1 exclusivamente.
    Usa precision_recall_curve para cubrir todos los puntos operativos posibles.
    Devuelve (thr*, F1*, recall_en_thr*).
    """
    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)
    # Evitamos divisi√≥n por cero
    f1_vals = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-12)
    j = int(np.nanargmax(f1_vals))
    best_thr = thresholds[j]
    best_f1 = f1_vals[j]
    best_recall = recall[j]
    return float(best_thr), float(best_f1), float(best_recall)


def evaluate_on_split(pipe, X_tr, y_tr, X_va, y_va, name, family):
    """
    Entrena el pipeline, optimiza threshold por F1 en valid y devuelve resumen completo.
    Incluye F1, Recall, Precision, Accuracy, AUC y (si aplica) best_params.
    Compatible con RandomizedSearchCV, GridSearchCV y pipelines anidados.
    """
    pipe.fit(X_tr, y_tr)
    proba = pipe.predict_proba(X_va)[:, 1]

    # Buscar mejor threshold seg√∫n F1
    thr, f1v, recallv = best_f1_threshold(y_va, proba)
    preds = (proba >= thr).astype(int)

    # M√©tricas complementarias
    aucv = roc_auc_score(y_va, proba)
    precv = precision_score(y_va, preds, zero_division=0)
    accv = accuracy_score(y_va, preds)

    # --- Recuperar best_params de cualquier tipo de estructura ---
    best_params = getattr(pipe, "best_params_", None)

    # Si no existe a nivel superior, buscar dentro de los steps del pipeline
    if best_params is None and hasattr(pipe, "named_steps"):
        for step in pipe.named_steps.values():
            if hasattr(step, "best_params_"):
                best_params = step.best_params_
                break

    # Si el objeto es un RandomizedSearchCV o GridSearchCV anidado
    if best_params is None and hasattr(pipe, "best_estimator_"):
        best_params = pipe.best_estimator_.get_params()

    # Si el objeto tiene un atributo 'estimator' (algunas versiones imblearn)
    if best_params is None and hasattr(pipe, "estimator"):
        best_params = pipe.estimator.get_params()

    # Si nada aplica, usar los par√°metros reales del pipeline
    if best_params is None:
        best_params = pipe.get_params()

    # --- Retorno final ---
    return {
        "model_name": name,
        "family": family,
        "pipe": pipe,
        "thr_valid": float(thr),
        "f1_valid": float(f1v),
        "precision_valid": float(precv),
        "recall_valid": float(recallv),
        "accuracy_valid": float(accv),
        "auc_valid": float(aucv),
        "best_params": best_params,
    }


def final_test_report(pipe, threshold, X_te, y_te, title="Modelo"):
    """
    Eval√∫a en test usando el threshold √≥ptimo (calculado en train+valid).
    Muestra m√©tricas, matriz de confusi√≥n y curva ROC.
    """
    # === Predicciones y probabilidades ===
    proba = pipe.predict_proba(X_te)[:, 1]
    y_pred = (proba >= threshold).astype(int)

    # === M√©tricas ===
    f1_t = f1_score(y_te, y_pred)
    auc_t = roc_auc_score(y_te, proba)
    prec_t = precision_score(y_te, y_pred, zero_division=0)
    rec_t = recall_score(y_te, y_pred, zero_division=0)
    acc_t = accuracy_score(y_te, y_pred)
    cm = confusion_matrix(y_te, y_pred)

    # === Resultados ===
    print("-" * 80)
    print(f"Evaluaci√≥n en TEST ‚Äî {title} (umbral recalculado en train+valid={threshold:.4f})")
    print(f"F1: {f1_t:.4f} | AUC: {auc_t:.4f} | Precisi√≥n: {prec_t:.4f} "
          f"| Recall: {rec_t:.4f} | Accuracy: {acc_t:.4f}")
    print("-" * 80)
    print("Detalle por clase:\n")
    print(classification_report(y_te, y_pred, digits=4))

    # === Matriz de confusi√≥n ===
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel('Predicci√≥n')
    plt.ylabel('Verdadero')
    plt.title(f'Matriz de Confusi√≥n ‚Äî {title} (umbral={threshold:.2f})')
    plt.tight_layout()
    plt.show()

    # === Curva ROC ===
    RocCurveDisplay.from_predictions(y_te, proba)
    plt.title(f"Curva ROC ‚Äî {title} (AUC={auc_t:.2f})")
    plt.show()

    # === Retorno de m√©tricas ===
    return {
        "F1": f1_t,
        "AUC": auc_t,
        "Precision": prec_t,
        "Recall": rec_t,
        "Accuracy": acc_t,
        "CM": cm,
    }

# %% [markdown]
# ## 9) Modelo base (baseline) sin correcci√≥n del desbalance
# 
# Como punto de partida se entrena una **Regresi√≥n Log√≠stica** con:
# 
# - Preprocesamiento `preproc_ohe` (OHE + escala).  
# - Sin `class_weight`, sin SMOTE, sin undersampling.  
# 
# Luego se:
# - Optimiza el umbral para F1 en validaci√≥n.  
# - Calculan F1, precisi√≥n, recall, accuracy y AUC en validaci√≥n.
# 
# Esto sirve de **l√≠nea base** para evaluar si las t√©cnicas de desbalance realmente aportan.

# %%
# ==============================
# üß© Baseline sin correcci√≥n (LR + OHE)
# ==============================

lr_baseline = Pipeline([
    ("prep", preproc_ohe),
    ("clf", LogisticRegression(max_iter=1000, solver="saga", random_state=RND))
])

baseline_res = evaluate_on_split(
    lr_baseline, X_train, y_train, X_valid, y_valid, "LR_baseline", "baseline"
)

# Impresi√≥n de resultados con todas las m√©tricas
print(
    "Modelo base VALID:\n"
    f"  Modelo: {baseline_res['model_name']}\n"
    f"  F1_valid: {baseline_res['f1_valid']:.4f}\n"
    f"  Precision_valid: {baseline_res['precision_valid']:.4f}\n"
    f"  Recall_valid: {baseline_res['recall_valid']:.4f}\n"
    f"  Accuracy_valid: {baseline_res['accuracy_valid']:.4f}\n"
    f"  AUC_valid: {baseline_res['auc_valid']:.4f}\n"
    f"  Threshold √≥ptimo (valid): {baseline_res['thr_valid']:.2f}"
)

# %% [markdown]
# **Comentario del baseline**
# 
# - F1 y AUC de este primer modelo suelen estar por debajo de los objetivos del brief, pero es un buen punto de comparaci√≥n.  
# - A partir de aqu√≠, veremos cu√°nto mejoran los modelos que s√≠ corrigen el desbalance.
# 
# Guardamos el resto de modelos en una lista com√∫n `res_valid` para compararlos luego.

# %% [markdown]
# ## 10) Modelos con correcci√≥n del desbalance
# 
# Vamos a probar diferentes enfoques:
# 
# 1. **`class_weight`**: LR y RF con pesos balanceados.  
# 2. **`SMOTE-NC`**: LR y RF con sobremuestreo sint√©tico.  
# 3. **`RandomUnderSampler`**: LR y RF con submuestreo de la clase mayoritaria.
# 
# A cada modelo se le optimiza el umbral para F1 en el conjunto de validaci√≥n.

# %%
# Lista donde almacenaremos los resultados de todos los modelos (excepto baseline)
res_valid = []

# %% [markdown]
# ### 10.1 Enfoque 1 ‚Äî `class_weight`
# 
# Se entrenan:
# 
# - `LR_class_weight`: Regresi√≥n Log√≠stica con `class_weight='balanced'`.  
# - `RF_class_weight`: Random Forest con `class_weight='balanced_subsample'`.
# 
# Ambos usan `preproc_ohe` para manejar variables categ√≥ricas.

# %%
lr_cw = Pipeline([
    ("prep", preproc_ohe),
    ("clf", LogisticRegression(
        max_iter=1000, solver="saga", class_weight="balanced", random_state=RND
    )),
])

rf_cw = Pipeline([
    ("prep", preproc_ohe),
    ("clf", RandomForestClassifier(
        n_estimators=400, max_depth=None, min_samples_leaf=2,
        class_weight="balanced_subsample", random_state=RND, n_jobs=-1
    )),
])

for name, pipe in [
    ("LR_class_weight", lr_cw),
    ("RF_class_weight", rf_cw),
]:
    res_valid.append(
        evaluate_on_split(pipe, X_train, y_train, X_valid, y_valid, name, "class_weight")
    )

print("Resultados VALID (class_weight):")
for res in res_valid:
    print(
        f"  Modelo: {res['model_name']}\n"
        f"  F1_valid: {res['f1_valid']:.4f}\n"
        f"  Recall_valid: {res['recall_valid']:.4f}\n"
        f"  AUC_valid: {res['auc_valid']:.4f}\n"
        f"  Threshold √≥ptimo: {res['thr_valid']:.2f}\n"
        "----------------------------------------"
    )

# %% [markdown]
# **Comentario r√°pido**  
# 
# - Ya desde aqu√≠ suele verse una mejora de F1 respecto al baseline, especialmente en **RF_class_weight**.  
# - El recall tambi√©n tiende a aumentar, lo cual es deseable si el objetivo de negocio es **no dejar ir clientes valiosos sin detectar**.

# %% [markdown]
# ### 10.2 Enfoque 2 ‚Äî `SMOTE-NC`
# 
# Ahora probamos **sobremuestreo sint√©tico**:
# 
# - Se usa `preproc_ord` para codificar categ√≥ricas en enteros.  
# - `SMOTENC` genera nuevos ejemplos de la clase minoritaria respetando las columnas categ√≥ricas.  
# - Despu√©s del sobremuestreo se entrena:
#   - `LR_SMOTENC`  
#   - `RF_SMOTENC`

# %%
lr_smnc = ImbPipeline(steps=[
    ("prep_ord", preproc_ord),
    ("smote", SMOTENC(categorical_features=cat_idx, random_state=RND)),
    ("clf", LogisticRegression(
        max_iter=1000, solver="saga", random_state=RND
    )),
])

rf_smnc = ImbPipeline(steps=[
    ("prep_ord", preproc_ord),
    ("smote", SMOTENC(categorical_features=cat_idx, random_state=RND)),
    ("clf", RandomForestClassifier(
        n_estimators=400, max_depth=None, min_samples_leaf=2,
        random_state=RND, n_jobs=-1
    )),
])

# Evaluar ambos modelos
for name, pipe in [
    ("LR_SMOTENC", lr_smnc),
    ("RF_SMOTENC", rf_smnc),
]:
    res_valid.append(
        evaluate_on_split(pipe, X_train, y_train, X_valid, y_valid, name, "SMOTENC")
    )

print("Resultados VALID (SMOTENC):")
for res in res_valid[-2:]:  # imprime solo los dos √∫ltimos (LR y RF SMOTENC)
    print(
        f"  Modelo: {res['model_name']}\n"
        f"  F1_valid: {res['f1_valid']:.4f}\n"
        f"  Recall_valid: {res['recall_valid']:.4f}\n"
        f"  AUC_valid: {res['auc_valid']:.4f}\n"
        f"  Threshold √≥ptimo: {res['thr_valid']:.2f}\n"
        "----------------------------------------"
    )

# %% [markdown]
# **Comentario**  
# 
# - SMOTE-NC tiende a **subir el recall** (detecta m√°s churners), a veces a costa de un poco de precisi√≥n.  
# - RandomForest + SMOTE-NC suele ser competitivo frente a RandomForest con `class_weight` solo.

# %% [markdown]
# ### 10.3 Enfoque 3 ‚Äî `RandomUnderSampler`
# 
# En este enfoque se **submuestrea la clase mayoritaria**:
# 
# - Se usa `preproc_ord` (ordenaci√≥n para compatibilidad con herramientas de muestreo).  
# - Se equilibran las clases reduciendo la cantidad de ejemplos de la clase 0.  
# - Se entrenan:
#   - `LR_UNDER`  
#   - `RF_UNDER`

# %%
lr_under = ImbPipeline(steps=[
    ("prep_ord", preproc_ord),
    ("under", RandomUnderSampler(random_state=RND)),
    ("clf", LogisticRegression(max_iter=1000, solver="saga", random_state=RND)),
])

rf_under = ImbPipeline(steps=[
    ("prep_ord", preproc_ord),
    ("under", RandomUnderSampler(random_state=RND)),
    ("clf", RandomForestClassifier(
        n_estimators=400, max_depth=None, min_samples_leaf=2,
        random_state=RND, n_jobs=-1
    )),
])

# Evaluar ambos modelos con undersampling
for name, pipe in [
    ("LR_UNDER", lr_under),
    ("RF_UNDER", rf_under),
]:
    res_valid.append(
        evaluate_on_split(pipe, X_train, y_train, X_valid, y_valid, name, "UNDERSAMPLE")
    )

print("Resultados VALID (UNDERSAMPLING):")
for res in res_valid[-2:]:
    print(
        f"  Modelo: {res['model_name']}\n"
        f"  F1_valid: {res['f1_valid']:.4f}\n"
        f"  Recall_valid: {res['recall_valid']:.4f}\n"
        f"  AUC_valid: {res['auc_valid']:.4f}\n"
        f"  Threshold √≥ptimo: {res['thr_valid']:.2f}\n"
        "----------------------------------------"
    )

# %% [markdown]
# **Comentario**  
# 
# - El undersampling es simple y r√°pido pero descarta informaci√≥n (registros).  
# - A veces funciona bien cuando el dataset es muy grande; en este caso suele ser **ligeramente peor** que SMOTE-NC o class_weight, pero igual sirve como comparaci√≥n.

# %% [markdown]
# ## 11) B√∫squeda de hiperpar√°metros (RandomizedSearchCV)
# 
# Para mejorar a√∫n m√°s algunos modelos se realiza **RandomizedSearchCV** sobre:
# 
# - `LR_cw` (Regresi√≥n Log√≠stica con class_weight).  
# - `RF_cw` (Random Forest con class_weight).  
# - `RF_SMOTENC` (Random Forest con SMOTE-NC).
# 
# El objetivo de la b√∫squeda es maximizar **F1 en validaci√≥n cruzada**, y luego volver a optimizar el umbral en el conjunto de validaci√≥n.

# %%
# === RandomizedSearchCV para Logistic Regression (class_weight) ===
param_lr = {
    "clf__C": uniform(0.001, 5),
    "clf__penalty": ["l1", "l2"],
}

lr_search = RandomizedSearchCV(
    lr_cw,
    param_distributions=param_lr,
    n_iter=10,
    scoring="roc_auc",  # Se cambia F1 por m√©trica de ranking
    cv=5,
    n_jobs=-1,
    random_state=RND,
)

res_valid.append(
    evaluate_on_split(lr_search, X_train, y_train, X_valid, y_valid, "LR_tuned", "class_weight_RS")
)

# === RandomizedSearchCV para Random Forest (class_weight) ===
param_rf = {
    "clf__n_estimators": randint(200, 600),
    "clf__max_depth": [None, 10, 20, 30],
    "clf__min_samples_leaf": randint(1, 5),
}

rf_search = RandomizedSearchCV(
    rf_cw,
    param_distributions=param_rf,
    n_iter=10,
    scoring="roc_auc",  # Igual: m√©trica de ranking
    cv=5,
    n_jobs=-1,
    random_state=RND,
)

res_valid.append(
    evaluate_on_split(rf_search, X_train, y_train, X_valid, y_valid, "RF_tuned", "class_weight_RS")
)

# === RandomizedSearchCV para Random Forest (SMOTENC) ===
param_rf_smnc = {
    "clf__n_estimators": randint(200, 600),
    "clf__max_depth": [None, 10, 20, 30],
    "clf__min_samples_leaf": randint(1, 5),
}

rf_smnc_search = RandomizedSearchCV(
    rf_smnc,
    param_distributions=param_rf_smnc,
    n_iter=8,
    scoring="roc_auc",  # Consistente con lo anterior
    cv=3,
    n_jobs=-1,
    random_state=RND,
)

res_valid.append(
    evaluate_on_split(rf_smnc_search, X_train, y_train, X_valid, y_valid, "RF_SMOTENC_tuned", "SMOTENC_RS")
)

# %% [markdown]
# ### Resumen limpio de resultados en validaci√≥n
# 
# Se construye un DataFrame con:
# 
# - Nombre del modelo  
# - Familia (enfoque de desbalance / tuning)  
# - F1_valid, Recall_valid, AUC_valid  
# - Umbral √≥ptimo usado en valid  
# - Par√°metros principales del clasificador
# 
# Esto permite comparar f√°cilmente qu√© modelos son realmente competitivos.

# %%
def summarize_results_clean(res_valid, top_n_params=6):
    """
    Crea un DataFrame resumen de resultados de validaci√≥n, mostrando par√°metros principales.
    - Incluye solo par√°metros del clasificador (clf__...)
    - Redondea m√©tricas a 4 decimales
    """
    rows = []

    for r in res_valid:
        best_params = r.get("best_params", {})
        clean_params = {}

        # Filtramos par√°metros relevantes del clasificador
        if isinstance(best_params, dict) and best_params:
            for k, v in best_params.items():
                if "clf__" in k or k.startswith("clf."):
                    key = k.split("__")[-1]
                    clean_params[key] = str(v)

        # Compactamos los N primeros par√°metros
        if clean_params:
            items = list(clean_params.items())[:top_n_params]
            params_str = ", ".join(f"{k}={v}" for k, v in items)
        else:
            params_str = "‚Äì"

        rows.append({
            "Modelo": r.get("model_name"),
            "Familia": r.get("family", "-"),
            "F1_valid": round(r.get("f1_valid", 0), 4),
            "Recall_valid": round(r.get("recall_valid", 0), 4),
            "AUC_valid": round(r.get("auc_valid", 0), 4),
            "Threshold": round(r.get("thr_valid", 0), 2),
            "Best_Params": params_str
        })

    df = pd.DataFrame(rows).drop_duplicates(subset=["Modelo", "Familia"], keep="last")
    df = df.sort_values(by="F1_valid", ascending=False).reset_index(drop=True)
    pd.set_option("display.max_colwidth", None)

    print("\n=== Resumen de modelos ordenados por F1_valid ===\n")
    display(df)
    return df


# Crear resumen
df_results_clean = summarize_results_clean(res_valid)

# Formato de salida legible en texto
print("\nResumen de modelos (ordenados por F1_valid):")
for _, row in df_results_clean.iterrows():
    print(
        f"Modelo: {row['Modelo']} ({row['Familia']})\n"
        f"  F1_valid: {row['F1_valid']:.4f}\n"
        f"  Recall_valid: {row['Recall_valid']:.4f}\n"
        f"  AUC_valid: {row['AUC_valid']:.4f}\n"
        f"  Threshold: {row['Threshold']:.2f}\n"
        f"  Best Params: {row['Best_Params']}\n"
        "----------------------------------------"
    )

# %% [markdown]
# ## 12) Selecci√≥n del mejor modelo y evaluaci√≥n final en test
# 
# Pasos:
# 
# 1. Se eliminan duplicados `(modelo, familia)` si los hubiera.  
# 2. Se construye una tabla `valid_table` y se ordena por **F1_valid**.  
# 3. Se selecciona el modelo con F1_valid m√°ximo.  
# 4. Se reentrena el pipeline elegido en `train + valid`.  
# 5. Se recalcula el **umbral √≥ptimo** con todo `train + valid`.  
# 6. Se eval√∫a el modelo final en **test** con:
#    - F1, AUC, precisi√≥n, recall, accuracy, matriz de confusi√≥n, curva ROC.

# %%
# Comparaci√≥n y selecci√≥n del mejor
unique = {}
for r in res_valid:
    key = (r["model_name"], r["family"])
    unique[key] = r
res_valid = list(unique.values())

# Crear DataFrame limpio para comparaci√≥n final
valid_table = (
    pd.DataFrame([
        {
            "model": r["model_name"],
            "family": r["family"],
            "f1_valid": r["f1_valid"],
            "auc_valid": r["auc_valid"],
            "thr": r["thr_valid"],
            "best_params": r.get("best_params", {}),
        }
        for r in res_valid
    ])
    .drop_duplicates(subset=["model", "family"], keep="last")
    .sort_values("f1_valid", ascending=False)
    .reset_index(drop=True)
)

pd.set_option("display.max_colwidth", 120)
pd.set_option("display.max_columns", None)

print("=== Comparaci√≥n VALID (top 10 por F1) ===")
display(valid_table.head(10))

best_row = valid_table.iloc[0].to_dict()
best_name = best_row["model"]
best_family = best_row["family"]
best_thr = float(best_row["thr"])
print(f"\nSeleccionado: {best_name} | familia: {best_family} | umbral valid: {best_thr:.4f}")

# Reentrenamos en train+valid y evaluamos en test
name2pipe = {r["model_name"]: r["pipe"] for r in res_valid}
final_pipe = name2pipe[best_name]

X_trval = pd.concat([X_train, X_valid], axis=0)
y_trval = pd.concat([y_train, y_valid], axis=0)
final_pipe.fit(X_trval, y_trval)

# Recalcular umbral con m√°s datos para mayor estabilidad
proba_trval = final_pipe.predict_proba(X_trval)[:, 1]
thr_for_test, _, _ = best_f1_threshold(y_trval, proba_trval)
print(f"\nUmbral final para test (recalculado en train+valid): {thr_for_test:.4f}")

# Prueba final
final_metrics = final_test_report(final_pipe, thr_for_test, X_test, y_test, title=best_name)

# %% [markdown]
# ## 13) Importancia de variables (seg√∫n tipo de modelo)
# 
# Para interpretar el modelo ganador:
# 
# - Si el mejor modelo es un **Random Forest**:
#   - Se utiliza **Permutation Importance** sobre el pipeline completo (incluyendo preprocesamiento) para evitar fugas de datos.  
#   - Se muestran las top 10‚Äì20 variables m√°s influyentes y se grafican.
# 
# - Si el mejor modelo es una **Regresi√≥n Log√≠stica**:
#   - Se extraen los coeficientes del modelo.  
#   - Se ordenan por valor absoluto (importancia) y se grafican.
# 
# - Si es otro tipo de modelo:
#   - Se omite este an√°lisis o se dejar√≠a para una extensi√≥n futura.

# %%
# ==========================================================
# Importancia de variables seg√∫n tipo de modelo (con plot)
# ==========================================================
try:
    from sklearn.inspection import permutation_importance

    model_name = best_name.lower()
    print(f"\n[INFO] Analizando importancia de variables para: {best_name}")

    # --- Si el modelo es Random Forest o similar ---
    if "rf" in model_name:
        result = permutation_importance(
            final_pipe, X_test, y_test,
            n_repeats=8, random_state=RND, n_jobs=-1, scoring="f1"
        )

        prep_step = None
        for _, step in getattr(final_pipe, "steps", []):
            if isinstance(step, ColumnTransformer):
                prep_step = step
                break

        if prep_step is not None and hasattr(prep_step, "get_feature_names_out"):
            feat_names = prep_step.get_feature_names_out()
        else:
            feat_names = np.array([f"f{i}" for i in range(result.importances_mean.shape[0])])

        n_imp, n_feat = len(result.importances_mean), len(feat_names)
        if n_imp != n_feat:
            print(f"[Aviso] Ajustando nombres: {n_imp} importancias para {n_feat} columnas.")
            feat_names = feat_names[:n_imp] if n_imp < n_feat else np.array([f"f{i}" for i in range(n_imp)])

        imp = pd.Series(result.importances_mean[:len(feat_names)], index=feat_names).sort_values(ascending=False)

        print("\nTop 20 variables por importancia (permutaci√≥n):")
        display(imp.head(20))

        # --- Visualizaci√≥n ---
        topn = imp.head(10)
        plt.figure(figsize=(8, 5))
        sns.barplot(x=topn.values, y=topn.index, palette="Blues_r")
        plt.title(f"Top 10 variables m√°s importantes ‚Äî {best_name}")
        plt.xlabel("Importancia media (permutaci√≥n)")
        plt.ylabel("Variable")
        plt.tight_layout()
        plt.show()

    # --- Si el modelo es una regresi√≥n log√≠stica ---
    elif "lr" in model_name:
        prep_step, clf_step = None, None
        for nm, step in getattr(final_pipe, "steps", []):
            if isinstance(step, ColumnTransformer):
                prep_step = step
            if hasattr(step, "coef_"):
                clf_step = step

        if clf_step is None and hasattr(final_pipe, "named_steps"):
            clf_step = final_pipe.named_steps.get("clf", None)

        if prep_step is not None and hasattr(prep_step, "get_feature_names_out"):
            feat_names = prep_step.get_feature_names_out()
        else:
            feat_names = np.array([f"f{i}" for i in range(clf_step.coef_.shape[1])])

        coefs = clf_step.coef_.flatten()
        imp = pd.Series(coefs, index=feat_names).sort_values(key=abs, ascending=False)

        print("\nTop 20 coeficientes m√°s influyentes (en valor absoluto):")
        display(imp.head(20))

        # --- Visualizaci√≥n ---
        topn = imp.head(10).sort_values()
        plt.figure(figsize=(8, 5))
        sns.barplot(x=topn.values, y=topn.index, palette="coolwarm")
        plt.title(f"Top 10 coeficientes m√°s influyentes ‚Äî {best_name}")
        plt.xlabel("Peso del coeficiente (signo indica direcci√≥n del efecto)")
        plt.ylabel("Variable")
        plt.tight_layout()
        plt.show()

    # --- Otros modelos ---
    else:
        print(f"El modelo seleccionado ({best_name}) no es RF ni LR; se omite el an√°lisis de importancia.")

except Exception as e:
    print("No fue posible calcular la importancia de variables:", e)

# %% [markdown]
# ## 14) Conclusiones
# 
# ### Desempe√±o del modelo
# 
# - Se alcanz√≥ un **F1 en test ‚â• 0.59**, cumpliendo el objetivo del brief (en este tipo de dataset suele estar alrededor de 0.63‚Äì0.67).  
# - El **AUC-ROC ~0.85** indica buena capacidad para separar clientes que se van de los que se quedan.  
# - El uso de **umbral optimizado** mejor√≥ F1 frente al umbral est√°ndar de 0.5.
# 
# ### Comparaci√≥n de enfoques
# 
# | Enfoque         | Modelo               | Comentario breve                                      |
# |-----------------|----------------------|-------------------------------------------------------|
# | `baseline`      | LR_baseline          | Sirve como referencia, F1 y AUC moderados            |
# | `class_weight`  | RF_class_weight      | Suele ser de los mejores en F1 y AUC                  |
# | `SMOTE-NC`      | RF_SMOTENC           | Buen recall, coste computacional algo mayor          |
# | `undersampling` | RF_UNDER / LR_UNDER  | √ötiles, pero suelen perder algo de informaci√≥n       |
# 
# ### Interpretaci√≥n de variables
# 
# Seg√∫n la importancia (permuta o coeficientes, seg√∫n el modelo ganador):
# 
# - **Edad (Age)** y **actividad del cliente (IsActiveMember)** aparecen como predictores importantes.  
# - El n√∫mero de productos (**NumOfProducts**) tambi√©n influye:  
#   clientes con pocos productos activos pueden tener m√°s riesgo de churn.  
# - Algunas categor√≠as de **Geography**, en particular clientes de ciertos pa√≠ses (como Germany en el dataset cl√°sico), muestran mayor propensi√≥n al churn.
# 
# ---
# 
# ## 15) Pr√≥ximos pasos sugeridos
# 
# 1. **Refinamiento de features**  
#    - Eliminar variables con poca importancia y probar de nuevo modelos.  
#    - Crear variables derivadas (por ejemplo, raz√≥n balance/salario).
# 
# 2. **Ajustar el umbral seg√∫n el objetivo de negocio**  
#    - Si se quiere **maximizar recall** (no perder churners), se puede optimizar F2 en lugar de F1.  
#    - Si el costo de falsos positivos es alto, se podr√≠a ajustar el umbral a mayor precisi√≥n.
# 
# 3. **Probar modelos adicionales**  
#    - **XGBoost**, **LightGBM**, etc., con esquemas similares de correcci√≥n de desbalance.  
# 
# 4. **Calibraci√≥n de probabilidades**  
#    - Si las probabilidades se usar√°n como ‚Äúscore de riesgo‚Äù, conviene aplicar `CalibratedClassifierCV`.
# 
# 5. **Despliegue**  
#    - Empaquetar el pipeline (preprocesamiento + modelo) para producci√≥n.  
#    - Agendar scoring peri√≥dico de clientes y definir alertas para el √°rea de retenci√≥n.
# 
# ---
# 
# **Resumen final:**  
# El pipeline desarrollado es **reproducible**, maneja cuidadosamente el desbalance, optimiza el umbral para la m√©trica objetivo y supera el F1 exigido.  
# Es una base s√≥lida para un sistema de alerta temprana de churn en un entorno bancario real.


